{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to create a database that can be accessed by users with different privileges. The final output of this notebook is illustrated in the diagram below and the following steps:\n",
    "\n",
    "* 1 - Create the database\n",
    "* 2 - Create the schema\n",
    "* 3 - Create the table\n",
    "    * 3.1 - Explore the different datatypes in the csv file\n",
    "    * 3.2 - Create a table with the most efficient datatype for each column\n",
    "    * 3.3 - Fill the boston_crimes table using data stored in a csv file (boston.csv)\n",
    "* 4 - Create user groups\n",
    "* 5 - Create users for each user group\n",
    "* 6 - Summary\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://dq-content.s3.amazonaws.com/250/goal.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start!!! \n",
    "\n",
    "\n",
    "![picture](https://i.imgflip.com/2xlv1w.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create the database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let' start by creating a database and a scheme. If we use an IKEA analogy, the database is the part of the store where all the products are store. The schema is the map that tells you where the different ailes are. So you know which aile to go to to find your product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 #to connect to postgres\n",
    "import getpass #to prompt user to insert password in a secure manner\n",
    "import csv #to read csv files\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prettytable import PrettyTable #to print tables in a neat pretty format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the database 'crime_db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crime_db database is already created\n"
     ]
    }
   ],
   "source": [
    "#indicate the parameters to connect to postgres\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "database = 'postgres' # this is the default database to connect to as we do not have any existing database yet\n",
    "username = 'postgres'\n",
    "#for security purposes, ask python to prompt you for the password\n",
    "password = getpass.getpass(prompt = 'Password:')\n",
    "\n",
    "#let's connect to the default database\n",
    "conn = psycopg2.connect(dbname = database,user = username, password = password)\n",
    "#Creating a databse cannot be part of a transaction block. This is because it requires access to the system catalogs which are outside the scope of a transaction. \n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "new_database_name = 'crime_db'\n",
    "#let us create the new database. If already created, we will print an appropriate message to convey that. \n",
    "try:\n",
    "    cur.execute(f'CREATE DATABASE {new_database_name};')\n",
    "except:\n",
    "    print(f'{new_database_name} database is already created')\n",
    "\n",
    "conn.autocommit = False\n",
    "conn.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create the Schema"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the schema crimes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema already exists\n"
     ]
    }
   ],
   "source": [
    "database = 'crime_db'\n",
    "schema_crimes = 'crimes'\n",
    "conn = psycopg2.connect(dbname = database, user = 'postgres', password = password)\n",
    "cur = conn.cursor()\n",
    "try:\n",
    "    cur.execute(f'CREATE SCHEMA {schema_crimes};')\n",
    "except:\n",
    "    print('Schema already exists')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep the connection open till the end of the project.\n",
    "\n",
    "By creating our database and schema, we now have this infrastructure:\n",
    "\n",
    "![picture](https://dq-content.s3.amazonaws.com/250/create_db.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Explore the different datatypes in the csv file\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us starting filling our schema with tables.\n",
    "First, we need to read our data to understand what data types we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has the following columns: ['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long'] \n",
      "\n",
      "The first row in the file has the following values: 1,619,LARCENY ALL OTHERS,2018-09-02,Sunday,42.35779134,-71.13937053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('boston.csv','r') as file:\n",
    "    #use first row as column headers\n",
    "    col_headers = next(file)\n",
    "    #split the string into a list of column names\n",
    "    col_headers = col_headers.split(',')\n",
    "    #remove the '\\n' from the last element\n",
    "    col_headers[-1] = col_headers[-1].strip('\\n')\n",
    "    #use next row after first as the first row with values\n",
    "    first_row = next(file)\n",
    "    print(f'The file has the following columns: {col_headers} \\n')\n",
    "    print(f'The first row in the file has the following values: {first_row}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to know how many unique values does each column take. This will help us in choosing the data type for each feature. I will do that by creating a dictionary where each key is the name of the column and the values correspond to the unique values that the this column/feature has. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_values = {}\n",
    "days_of_the_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday','Friday','Saturday','Sunday'] \n",
    "with open('boston.csv','r') as file:\n",
    "    #skip the header\n",
    "    next(file)\n",
    "    #read the file into rows \n",
    "    rows = csv.reader(file)\n",
    "    i=0\n",
    "    for row in rows:\n",
    "        i=i+1\n",
    "        for column in col_headers:\n",
    "            #for each column find the row index that has its value\n",
    "            column_index = col_headers.index(column)\n",
    "            if column in data_values:\n",
    "                #use the column index to add the corresponding row value to the dictionary (using add to make sure only unique values are saved)\n",
    "                data_values[column].add(row[column_index])\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                data_values[column] = set([row[column_index]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the number of unique values that each column/feature has. This will inform our decision of the most approprate data type to use when saving it in our database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_values.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incident_number has 298329 unique values. One example is ------> 149914\n",
      "\n",
      "offense_code has 219 unique values. One example is ------> 3501\n",
      "\n",
      "description has 239 unique values. One example is ------> M/V ACCIDENT INVOLVING PEDESTRIAN - INJURY\n",
      "\n",
      "date has 1177 unique values. One example is ------> 2017-09-08\n",
      "\n",
      "day_of_the_week has 7 unique values. One example is ------> Sunday\n",
      "\n",
      "lat has 18177 unique values. One example is ------> 42.29817352\n",
      "\n",
      "long has 18177 unique values. One example is ------> -71.06175129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, values in data_values.items():\n",
    "    print(f'{key} has {len(data_values[key])} unique values. One example is ------> {next(iter(values))}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of all the columns already give us an idea of what the most memory-efficient data type is to represent them. Let us the range for each data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_range(column):\n",
    "    ''' Finds the range [min,max] and data type for each column\n",
    "    Arguments:\n",
    "    ==========\n",
    "    * column: a set taking from a dictionary\n",
    "    Returns:\n",
    "    ========\n",
    "     * min: min value in the column set. The type depends on the datatype of values in column (int, float). For strings, it will return the size of shortest string\n",
    "     * min: max value in the column set. The type depends on the datatype of values in column (int, float). For strings, it will return the size of longest string\n",
    "     * data_type: string containing the datatype of the column\n",
    "     '''\n",
    "    #set the min/max to dummy values\n",
    "    max_value = -np.Inf\n",
    "    min_value = np.Inf\n",
    "    #iterate over each item of the column\n",
    "    for item in column:\n",
    "        #try if the item type is an integer\n",
    "        try:\n",
    "            item = int(item)\n",
    "            if item > max_value:\n",
    "                    max_value = item\n",
    "            if item < min_value:\n",
    "                min_value = item\n",
    "        #if that gives an error, then it is a string or a date\n",
    "        except:\n",
    "            try:\n",
    "                item = float(item)\n",
    "                if item > max_value:\n",
    "                        max_value = item\n",
    "                if item < min_value:\n",
    "                    min_value = item\n",
    "            except:\n",
    "                if len(item) > max_value:\n",
    "                    max_value = len(item)\n",
    "                if len(item) < min_value:\n",
    "                    min_value = len(item)\n",
    "\n",
    "    data_type = type(item)              \n",
    "    return data_type, min_value, max_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incident_number has 298,329 unique values, is of datatype <class 'int'> and ranges between (1,298329). One example is ------> 149914\n",
      "\n",
      "offense_code has 219 unique values, is of datatype <class 'int'> and ranges between (111,3831). One example is ------> 3501\n",
      "\n",
      "description has 239 unique values, is of datatype <class 'str'> and ranges between (5,58). One example is ------> M/V ACCIDENT INVOLVING PEDESTRIAN - INJURY\n",
      "\n",
      "date has 1,177 unique values, is of datatype <class 'str'> and ranges between (10,10). One example is ------> 2017-09-08\n",
      "\n",
      "day_of_the_week has 7 unique values, is of datatype <class 'str'> and ranges between (6,9). One example is ------> Sunday\n",
      "\n",
      "lat has 18,177 unique values, is of datatype <class 'float'> and ranges between (42.2324133,42.39504158). One example is ------> 42.29817352\n",
      "\n",
      "long has 18,177 unique values, is of datatype <class 'float'> and ranges between (-71.17867378,-70.96367615). One example is ------> -71.06175129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for key, values in data_values.items():\n",
    "#     print(f'{key} has {len(data_values[key])} unique values. One example is ------> {next(iter(values))}\\n')\n",
    "for key, values in data_values.items():\n",
    "    data_type, min_value, max_value = find_range(values)\n",
    "    print(f'{key} has {len(data_values[key]):,} unique values, is of datatype {data_type} and ranges between ({min_value},{max_value}). One example is ------> {next(iter(values))}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the information we now have, let us associate a datatype to each column:\n",
    "* **incident number** -> **INT** (should be good as long as we have less than 2.1 billion incidents)\n",
    "\n",
    "* **offense_code** -> **SMALLINT** (as long as we have less than 32,000 offense_codes. At present, offense codes are between 111-3,831)\n",
    "\n",
    "* **description** -> **VARCHAR(120)** (the maximum description has 58 characeters let us round that to 60 and double it to be on the safe side)\n",
    "\n",
    "* **date** -> DATE\n",
    "\n",
    "* **day_of_the_week** -> **VARCHAR(9)** (wednesday has 9 letters). However, I will replace that with ENUM datatype. It will transform the datatype from string to integer.\n",
    "\n",
    "* **lat** -> **DECIMAL(10,8)** 10 digits in total with 8 after the decimal point\n",
    "\n",
    "* **long** -> **DECIMAL(10,8)** 10 digits in total with 8 after the decimal point"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create some enumerated datatypes to optimise memory use. I will choose day_of_the_week. offense_code and description can be enumerated as well but they would require some python to iterate over all unique values. Otherwise, logging them manually will be very tedious and is not the objective of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Create a table with the most efficient datatype for each column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENUM dataype already exists\n"
     ]
    }
   ],
   "source": [
    "sql_command =f\"CREATE TYPE enum_day_of_the_week AS ENUM {data_values['day_of_the_week']};\"\n",
    "sql_command = sql_command.replace('{','(').replace('}',')')\n",
    "try:\n",
    "    cur.execute(sql_command)\n",
    "except:\n",
    "    print('ENUM dataype already exists')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us create our table in the crimes schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cur.execute('''\n",
    "                CREATE TABLE crimes.boston_crimes (\n",
    "                    incident_number INT PRIMARY KEY,\n",
    "                    offense_code SMALLINT,\n",
    "                    description VARCHAR(120),\n",
    "                    date DATE,\n",
    "                    day_of_the_week enum_day_of_the_week,\n",
    "                    lat DECIMAL(10,8),\n",
    "                    long DECIMAL(10,8)\n",
    "                );\n",
    "    ''')\n",
    "except:\n",
    "    print('Table already exists')\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check our table and the datatypes of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('incident_number', 'integer')\n",
      "('offense_code', 'smallint')\n",
      "('description', 'character varying')\n",
      "('date', 'date')\n",
      "('day_of_the_week', 'USER-DEFINED')\n",
      "('lat', 'numeric')\n",
      "('long', 'numeric')\n"
     ]
    }
   ],
   "source": [
    "query = ''' \n",
    "SELECT column_name, data_type\n",
    "FROM information_schema.columns\n",
    "WHERE table_schema = 'crimes'\n",
    "  AND table_name = 'boston_crimes';'''\n",
    "\n",
    "results = cur.execute(query)\n",
    "results = cur.fetchall()\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All looking good! Now let us use the csv file to fill the table."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Fill the boston_crimes table using data stored in a csv file (boston.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already loaded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('boston.csv','r') as file:\n",
    "        cur.copy_expert(\"COPY crimes.boston_crimes FROM STDIN WITH CSV HEADER;\", file)\n",
    "except:\n",
    "    print('File already loaded')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check that the table was successfully loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+--------------------------------------------+------------+-----------------+-------------+--------------+\n",
      "| incident_number | offense_code |                description                 |    date    | day_of_the_week |     lat     |     long     |\n",
      "+-----------------+--------------+--------------------------------------------+------------+-----------------+-------------+--------------+\n",
      "|        1        |     619      |             LARCENY ALL OTHERS             | 2018-09-02 |      Sunday     | 42.35779134 | -71.13937053 |\n",
      "|        2        |     1402     |                 VANDALISM                  | 2018-08-21 |     Tuesday     | 42.30682138 | -71.06030035 |\n",
      "|        3        |     3410     |            TOWED MOTOR VEHICLE             | 2018-09-03 |      Monday     | 42.34658879 | -71.07242943 |\n",
      "|        4        |     3114     |            INVESTIGATE PROPERTY            | 2018-09-03 |      Monday     | 42.33418175 | -71.07866441 |\n",
      "|        5        |     3114     |            INVESTIGATE PROPERTY            | 2018-09-03 |      Monday     | 42.27536542 | -71.09036101 |\n",
      "|        6        |     3820     | M/V ACCIDENT INVOLVING PEDESTRIAN - INJURY | 2018-09-03 |      Monday     | 42.29019621 | -71.07159012 |\n",
      "|        7        |     724      |                 AUTO THEFT                 | 2018-09-03 |      Monday     | 42.30607218 | -71.08273260 |\n",
      "|        8        |     3301     |               VERBAL DISPUTE               | 2018-09-03 |      Monday     | 42.32701648 | -71.10555088 |\n",
      "|        9        |     301      |              ROBBERY - STREET              | 2018-09-03 |      Monday     | 42.33152148 | -71.07085307 |\n",
      "|        10       |     3301     |               VERBAL DISPUTE               | 2018-09-03 |      Monday     | 42.29514664 | -71.05860832 |\n",
      "+-----------------+--------------+--------------------------------------------+------------+-----------------+-------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "conn.commit()\n",
    "query = ''' SELECT * FROM crimes.boston_crimes LIMIT 10'''\n",
    "\n",
    "cur.execute(query)\n",
    "\n",
    "rows = cur.fetchall()\n",
    "\n",
    "table = PrettyTable(col_headers)\n",
    "for row in rows:\n",
    "    table.add_row(row)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now doesn't that look pretty!!!!\n",
    "\n",
    "![picture](https://media.tenor.com/Osi-RwGWBwIAAAAM/pretty-i-feel-pretty.gif)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now added our first table into our crimes schema. Here is an updated diagram of my progress:\n",
    "\n",
    "![picture](https://dq-content.s3.amazonaws.com/250/table_created.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to create user groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Create user groups\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to add two user groups: readonly and readwrite. First, let me make sure that there are no privileges inherited from the public group and on the public schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#revoke all privileges of the public group on the public schema\n",
    "cur.execute('REVOKE ALL ON SCHEMA public FROM public')\n",
    "#revoke all privileges of public on the crime_db database\n",
    "cur.execute('REVOKE ALL ON DATABASE crime_db FROM public')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No I am sure no user group will inadvertently inherit privileges from the public group, I can create two new user groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a group with NOLOGIN option. We want to make sure groups are not used to login. Login should be only done by providing a user\n",
    "#create readonly group\n",
    "cur.execute('CREATE GROUP readonly NOLOGIN;')\n",
    "#create readwrite group\n",
    "cur.execute('CREATE GROUP readwrite NOLOGIN;')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us select the privileges suitable for each group:\n",
    "* The readonly group is supposed to only have privileges to perform SELECT queries\n",
    "* The readwrite group to be able to perform SELECT, INSERT, DELETE, and UPDATE queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grant SELECT privileges to readyonly group\n",
    "cur.execute('GRANT SELECT ON ALL TABLES IN SCHEMA crimes TO readonly')\n",
    "#grant SELECT, INSERT, DELETE and UPDATE privileges to readwrite group\n",
    "cur.execute('GRANT SELECT, INSERT, DELETE, UPDATE ON ALL TABLES IN SCHEMA crimes TO readwrite')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us give both groups the privilege to connect and use all tables in the crimes_db database and the crimes schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('GRANT CONNECT ON DATABASE crime_db TO readonly')\n",
    "cur.execute('GRANT CONNECT ON DATABASE crime_db TO readwrite')\n",
    "cur.execute('GRANT USAGE ON SCHEMA crimes TO readonly')\n",
    "cur.execute('GRANT USAGE ON SCHEMA crimes TO readwrite')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us create new users for each user group!\n",
    "\n",
    "![picture](https://i.swncdn.com/media/800w/via/images/2022/07/01/26215-minions-universal-2_source_file.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Create users for each user group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "#create a data_analyst with password 'secret1'\n",
    "cur.execute(\"CREATE USER data_analyst WITH PASSWORD 'secret1'\")\n",
    "#assign the user to the readonly group\n",
    "cur.execute(\"GRANT readonly TO data_analyst\")\n",
    "#create a data_scientist with password 'secret2'\n",
    "cur.execute(\"CREATE USER data_scientist WITH PASSWORD 'secret2'\")\n",
    "#assign the user to readwrite group\n",
    "cur.execute(\"GRANT readwrite TO data_scientist\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us do some tests to make sure everything as we expect it to be: \n",
    "* Does the readwrite user group has the correct privileges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('''SELECT grantee, privilege_type\n",
    "    FROM information_schema.table_privileges\n",
    "    WHERE grantee = 'readwrite'; ''')\n",
    "cur.fetchall()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Does the readonly user group has the correct privileges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('readonly', 'SELECT')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('''SELECT grantee, privilege_type\n",
    "    FROM information_schema.table_privileges\n",
    "    WHERE grantee = 'readonly'; ''')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achieved the objective of this notebook: \n",
    "* Created a crime_db database\n",
    "* Create a crimes schema\n",
    "* Created a boston_crimes table in crimes schema (read from a csv file)\n",
    "* Created two user groups with different privileges\n",
    "* Created a user in each user group \n",
    "\n",
    "\n",
    "![picture](https://dq-content.s3.amazonaws.com/250/goal.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
